{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8182871,"sourceType":"datasetVersion","datasetId":4844838},{"sourceId":8176869,"sourceType":"datasetVersion","datasetId":4840287},{"sourceId":8182149,"sourceType":"datasetVersion","datasetId":4844381},{"sourceId":8174424,"sourceType":"datasetVersion","datasetId":4838472},{"sourceId":1460420,"sourceType":"datasetVersion","datasetId":856362}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-21T10:42:27.350487Z","iopub.execute_input":"2024-04-21T10:42:27.350849Z","iopub.status.idle":"2024-04-21T10:42:27.707326Z","shell.execute_reply.started":"2024-04-21T10:42:27.350820Z","shell.execute_reply":"2024-04-21T10:42:27.706326Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/input/news-processed-dataset/keywords.pickle\n/kaggle/input/news-processed-dataset/full_data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from collections import Counter\nimport pandas as pd\n\nresults = Counter()\n\ndata = pd.read_csv(\"/kaggle/input/rambler-dataset/file.csv\", sep=\";\", names=[\"Title\", \"Description\", \"Article Text\", \"Keywords\"])\ndata.Keywords.apply(lambda x: list(map(lambda y: y[1:-1].lower(), x[1:-1].split(\", \")))).apply(results.update)\ndata = pd.read_csv(\"/kaggle/input/russian-news-2020/news.csv\")\ndata.tags.dropna().str.lower().str.split(\", \").apply(results.update)\nfor sheet_name in range(4):\n    data = pd.read_excel(\"/kaggle/input/vk-mail-dataset/data.mail.xlsx\", sheet_name = sheet_name)\n    data.Keywords.str.lower().str.split(\", \").apply(results.update)\n\nif \"\" in results:\n    del results[\"\"]\n\nprint(\"Total keywords:\", len(results))\nprint(\"Total rows with defined keywords:\", sum(results.values()))\nprint(\"Total keywords with count >= 30:\", len([keyword for keyword, count in results.items() if count >= 30]))\nprint(\"Total keywords with count >= 50:\", len([keyword for keyword, count in results.items() if count >= 50]))\nprint(\"Total keywords with count >= 80:\", len([keyword for keyword, count in results.items() if count >= 80]))\n\nkeyword_2_id = dict()\nid_2_keyword = []\nfor i, word in enumerate([keyword for keyword, count in results.items() if count >= 80]):\n    keyword_2_id[word] = i\n    id_2_keyword.append(word)\n\nimport pickle\nwith open('/kaggle/working/keywords.pickle', 'wb') as handle:\n    pickle.dump((keyword_2_id, id_2_keyword), handle, protocol=pickle.HIGHEST_PROTOCOL)\n\nwith open('/kaggle/working/keywords.pickle', 'rb') as handle:\n    keyword_2_id_, id_2_keyword_ = pickle.load(handle)\n    assert keyword_2_id_ == keyword_2_id and id_2_keyword_ == id_2_keyword","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:04:37.581671Z","iopub.execute_input":"2024-04-21T12:04:37.582222Z","iopub.status.idle":"2024-04-21T12:05:23.652309Z","shell.execute_reply.started":"2024-04-21T12:04:37.582192Z","shell.execute_reply":"2024-04-21T12:05:23.651369Z"},"trusted":true},"execution_count":113,"outputs":[{"name":"stdout","text":"Total keywords: 8281\nTotal rows with defined keywords: 158220\nTotal keywords with count >= 30: 385\nTotal keywords with count >= 50: 257\nTotal keywords with count >= 80: 190\n","output_type":"stream"}]},{"cell_type":"code","source":"sorted(results.values())[-10:]","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:34:43.572749Z","iopub.execute_input":"2024-04-21T12:34:43.573154Z","iopub.status.idle":"2024-04-21T12:34:43.581166Z","shell.execute_reply.started":"2024-04-21T12:34:43.573123Z","shell.execute_reply":"2024-04-21T12:34:43.580216Z"},"trusted":true},"execution_count":135,"outputs":[{"execution_count":135,"output_type":"execute_result","data":{"text/plain":"[2913, 3147, 3295, 3601, 3736, 4015, 6266, 7547, 7728, 19825]"},"metadata":{}}]},{"cell_type":"code","source":"print([keyword for keyword, count in results.items() if count >= 1000])","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:35:41.808091Z","iopub.execute_input":"2024-04-21T12:35:41.808469Z","iopub.status.idle":"2024-04-21T12:35:41.814992Z","shell.execute_reply.started":"2024-04-21T12:35:41.808438Z","shell.execute_reply":"2024-04-21T12:35:41.814092Z"},"trusted":true},"execution_count":137,"outputs":[{"name":"stdout","text":"['экономика', 'в мире', 'москва', 'общество', 'россия', 'происшествия', 'сша', 'lenta.ru', 'распространение нового коронавируса', 'коронавирус в россии', 'коронавирус covid-19', 'культура', 'туризм', 'питание', 'семья', 'статья', 'новость', 'газета.ру', 'образ жизни', 'наука и практика', 'общество и государство', 'город', 'интерьеры', 'дети 3-7 лет']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Keyword labeling (loading)","metadata":{}},{"cell_type":"code","source":"import pickle\n\ndef get_keyword_vector(keywords):\n    keyword_vector = [0.]*len(keyword_2_id)\n    for keyword in keywords:\n        id_ = keyword_2_id.get(keyword)\n        if id_ is not None:\n            keyword_vector[id_] = 1.\n    return keyword_vector\n\nkeyword_2_id, id_2_keyword = [], []\nwith open('/kaggle/input/news-processed-dataset/keywords.pickle', 'rb') as handle:\n    keyword_2_id, id_2_keyword = pickle.load(handle)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T10:42:29.871130Z","iopub.execute_input":"2024-04-21T10:42:29.871691Z","iopub.status.idle":"2024-04-21T10:42:29.879372Z","shell.execute_reply.started":"2024-04-21T10:42:29.871643Z","shell.execute_reply":"2024-04-21T10:42:29.878297Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Model RuBert Loading","metadata":{}},{"cell_type":"code","source":"!pip install gdown\n!gdown http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_pt.tar.gz\n!tar -xzf rubert_cased_L-12_H-768_A-12_pt.tar.gz\n#!pip install transformers\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport os\nimport json\n\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn\nfrom transformers import BertModel, BertTokenizer","metadata":{"execution":{"iopub.status.busy":"2024-04-21T10:42:32.228588Z","iopub.execute_input":"2024-04-21T10:42:32.229347Z","iopub.status.idle":"2024-04-21T10:43:30.976299Z","shell.execute_reply.started":"2024-04-21T10:42:32.229305Z","shell.execute_reply":"2024-04-21T10:43:30.975356Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /opt/conda/lib/python3.10/site-packages (5.1.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.13.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.2.2)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading...\nFrom: http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_pt.tar.gz\nTo: /kaggle/working/rubert_cased_L-12_H-768_A-12_pt.tar.gz\n100%|████████████████████████████████████████| 662M/662M [00:32<00:00, 20.3MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"with open(\"rubert_cased_L-12_H-768_A-12_pt/bert_config.json\", \"r\") as read_file, open(\"rubert_cased_L-12_H-768_A-12_pt/config.json\", \"w\") as conf:\n    file = json.load(read_file)\n    conf.write(json.dumps(file))\n!rm rubert_cased_L-12_H-768_A-12_pt/bert_config.json","metadata":{"execution":{"iopub.status.busy":"2024-04-21T10:43:30.978817Z","iopub.execute_input":"2024-04-21T10:43:30.979398Z","iopub.status.idle":"2024-04-21T10:43:31.990485Z","shell.execute_reply.started":"2024-04-21T10:43:30.979361Z","shell.execute_reply":"2024-04-21T10:43:31.989142Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('rubert_cased_L-12_H-768_A-12_pt')\nmodel = BertModel.from_pretrained('rubert_cased_L-12_H-768_A-12_pt', output_hidden_states = True)\n\ndef mean_pooling(model_output, attention_mask):\n    token_embeddings = model_output['last_hidden_state']\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n    return sum_embeddings / sum_mask","metadata":{"execution":{"iopub.status.busy":"2024-04-21T10:43:31.992040Z","iopub.execute_input":"2024-04-21T10:43:31.992350Z","iopub.status.idle":"2024-04-21T10:43:33.269331Z","shell.execute_reply.started":"2024-04-21T10:43:31.992321Z","shell.execute_reply":"2024-04-21T10:43:33.268347Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Combining dataset (from three relevant to keywords)","metadata":{}},{"cell_type":"code","source":"full_data = pd.read_csv(\"/kaggle/input/rambler-dataset/file.csv\", sep=\";\", names=[\"Title\", \"Description\", \"Article Text\", \"Keywords\"])\nfull_data = full_data[['Title', 'Description', 'Article Text', 'Keywords']]\nfull_data[\"Keywords\"] = full_data.Keywords.apply(lambda x: list(map(lambda y: y[1:-1].lower(), x[1:-1].split(\", \")))).apply(\", \".join)\ndf = pd.read_csv(\"/kaggle/input/russian-news-2020/news.csv\")\ndf = df[['title', 'text', 'tags']]\ndf.columns = ['Title', 'Article Text', 'Keywords']\ndf[\"Description\"] = \"\"\ndf[\"Keywords\"] = data.Keywords.dropna().str.lower().str.split(\", \").apply(\", \".join)\nfull_data = pd.concat([full_data,df], axis=0, ignore_index = True)\nfor sheet_name in range(4):\n    data = pd.read_excel(\"/kaggle/input/vk-mail-dataset/data.mail.xlsx\", sheet_name = sheet_name)\n    data = data[['Title', 'Description', 'Article Text', 'Keywords']]\n    data.Keywords = data.Keywords.str.lower().str.split(\", \").apply(\", \".join)\n    full_data = pd.concat([full_data,data], axis=0, ignore_index = True)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:22:22.665154Z","iopub.execute_input":"2024-04-21T12:22:22.665519Z","iopub.status.idle":"2024-04-21T12:23:08.401092Z","shell.execute_reply.started":"2024-04-21T12:22:22.665488Z","shell.execute_reply":"2024-04-21T12:23:08.400214Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"full_data.to_csv(\"/kaggle/working/full_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:23:50.237212Z","iopub.execute_input":"2024-04-21T12:23:50.238108Z","iopub.status.idle":"2024-04-21T12:23:59.828587Z","shell.execute_reply.started":"2024-04-21T12:23:50.238070Z","shell.execute_reply":"2024-04-21T12:23:59.827573Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"class KeywordsDataset(Dataset):\n    def __init__(self, path, tokenizer=None, only_keywords=True, only_title=False):\n        self.data = full_data\n        # Title,Article Text,Description,Keywords\n        self.only_keywords = only_keywords\n        if only_keywords:\n            self.data = self.data[self.data['Keywords'].notna()]\n            self.data = self.data[self.data['Description'].notna()]\n            self.data = self.data[self.data['Title'].notna()]\n            self.keywords = self.data.Keywords.str.lower().str.split(\", \")\n            self.keywords = np.array([get_keyword_vector(self.keywords.iloc[index]) for index in range(len(self.keywords))])\n            indices = [i for i, k in enumerate(self.keywords) if sum(k) > 0]\n            self.data.reset_index(inplace=True)\n            self.data = self.data.loc[indices, :]\n            self.data = self.data.loc[:, [\"Title\", \"Article Text\", \"Description\", \"Keywords\"]]\n            self.keywords = self.keywords[indices]        \n        if only_title:\n            self.data = self.data[self.data['Class'].notna()]\n        self.data.reset_index(inplace=True)\n        self.tokenizer = tokenizer\n        \n    def __len__(self):\n        return self.data.shape[0]\n\n    def tokenize(self, text):\n        if self.tokenizer is None:\n            return {\"text\" : text}\n        return self.tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=100)\n\n    def __getitem__(self, index):\n        row = self.data.iloc[index]\n        united_text = \"; \".join([row.Title, row.Description, \"\"]) #row[\"Article Text\"][:50]])\n        items = {k: v.reshape(-1) for k, v in self.tokenize(united_text).items()}\n        if self.only_keywords:\n            items[\"keywords\"] = torch.tensor(self.keywords[index])\n        return items","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:25:20.263933Z","iopub.execute_input":"2024-04-21T12:25:20.264273Z","iopub.status.idle":"2024-04-21T12:25:20.277907Z","shell.execute_reply.started":"2024-04-21T12:25:20.264246Z","shell.execute_reply":"2024-04-21T12:25:20.276847Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/news-processed-dataset/full_data.csv\"\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nbatch_size = 64\nlearning_rate = 1e-3\nnum_epochs = 10\nnum_workers = 2 if device.type == \"cuda\" else None\nnumber_keywords = len(keyword_2_id)\nembedding_dim = 768\n\nfull_dataset = KeywordsDataset(path, tokenizer=tokenizer, only_keywords=True)\ntrain_size = int(0.8 * len(full_dataset))\ntest_size = len(full_dataset) - train_size\ntrain_dataset, eval_dataloader = torch.utils.data.random_split(full_dataset, [train_size, test_size])\ntrain_dataloader, eval_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers), DataLoader(eval_dataloader, batch_size=batch_size, shuffle=False, num_workers=num_workers)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:25:28.407782Z","iopub.execute_input":"2024-04-21T12:25:28.408123Z","iopub.status.idle":"2024-04-21T12:25:33.921576Z","shell.execute_reply.started":"2024-04-21T12:25:28.408096Z","shell.execute_reply":"2024-04-21T12:25:33.920780Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"class KeywordClassifier(nn.Module):\n    def __init__(self, embedding_dim, num_classes):\n        super(KeywordClassifier, self).__init__()\n        self.fc1 = nn.Linear(embedding_dim, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, num_classes)\n        self.activation = nn.ReLU()\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, embeddings):\n        x = self.fc1(embeddings)\n        x = self.activation(x)\n        x = self.fc2(x)\n        x = self.activation(x)\n        logits = self.fc3(x)\n        return self.sigmoid(logits)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:26:00.964454Z","iopub.execute_input":"2024-04-21T12:26:00.965285Z","iopub.status.idle":"2024-04-21T12:26:00.972242Z","shell.execute_reply.started":"2024-04-21T12:26:00.965250Z","shell.execute_reply":"2024-04-21T12:26:00.971245Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel.to(device)\nmodel.eval()\nclassifier_model = KeywordClassifier(embedding_dim, number_keywords).to(device)\nloss_fn = nn.BCELoss()\noptimizer = torch.optim.Adam(classifier_model.parameters(), lr=1e-4)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predicted_keywords(logits, id_2_keyword, top_keywords=10):\n    top_k_values, top_k_indices = logits.topk(top_keywords, dim=1)\n    predicted_keywords = []\n    for i in range(logits.shape[0]):\n        predicted_keywords.append([id_2_keyword[idx.item()] for idx in top_k_indices[i]])\n    return predicted_keywords","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_keywords(title, description, text, top_keywords=10):\n    model.eval()\n    classifier_model.eval()\n    with torch.no_grad():\n        text = \"; \".join([title, description, \"\"])\n        tokenized = tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=100)\n        items = {k: v.reshape(1, -1).to(device) for k, v in tokenized.items()}\n        outputs = model(**items)\n        embeddings = mean_pooling(outputs, items['attention_mask'])\n        # print(\"embeddings: \", embeddings[0][:10])\n        logits = classifier_model(embeddings).cpu() # expit\n    # print(\"Logits\", logits[0][:10])\n    return get_predicted_keywords(logits, id_2_keyword, top_keywords)[0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_history = []\n\nfor epoch in range(num_epochs):\n    batch_losses = []\n    for n_batch, batch in enumerate(tqdm(train_dataloader)):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        keywords = batch.pop(\"keywords\", None)\n        with torch.no_grad():\n            outputs = model(**batch)\n            embeddings = mean_pooling(outputs, batch['attention_mask'])\n        logits = classifier_model(embeddings)\n        loss = loss_fn(logits, keywords.float())\n        batch_losses.append(loss.item())\n        if n_batch%40 == 0:\n            accuracy = (logits.argmax(dim=1) == keywords.argmax(dim=1)).float().mean()\n            print(f\"Batch: {n_batch}, Loss: {loss.item()}, Accuracy: {accuracy.item()}\") \n        \n        if n_batch%100 == 0:\n            for i_row in [10, 16]:\n                row = full_dataset.data.iloc[i_row]\n                print(\"Text: \", row.Title, row.Description)\n                res = predict_keywords(row.Title, row.Description, \"\", top_keywords=4)\n                print(\"Predicted:\", \", \".join(res))\n                print(\"-----------\")\n        \n        loss.backward()\n        optimizer.step()\n\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': classifier_model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'loss_history': loss_history,\n    }, f\"/kaggle/working/checkpoint_{epoch}.pt\")\n\n    loss_history.append(np.mean(batch_losses))\n    print(f\"Epoch: {epoch}, Loss: {loss_history[-1]}\") #, Accuracy: {accuracy.item()}\")\n\nwith torch.no_grad():\n    for n_batch, batch in enumerate(tqdm(eval_dataloader)):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        keywords = batch.pop(\"keywords\", None)\n        outputs = model(**batch)\n        embeddings = mean_pooling(outputs, batch['attention_mask'])\n        logits = classifier_model(embeddings)\n        loss = loss_fn(logits, keywords)\n        accuracy = (logits.argmax(dim=1) == keywords.argmax(dim=1)).float().mean()\n        print(f\"Loss: {loss.item()}, Accuracy: {accuracy.item()}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:53:57.048517Z","iopub.execute_input":"2024-04-21T12:53:57.048911Z","iopub.status.idle":"2024-04-21T12:56:47.726322Z","shell.execute_reply.started":"2024-04-21T12:53:57.048879Z","shell.execute_reply":"2024-04-21T12:56:47.724942Z"},"trusted":true},"execution_count":147,"outputs":[{"name":"stderr","text":"  0%|          | 1/1110 [00:00<11:09,  1.66it/s]","output_type":"stream"},{"name":"stdout","text":"Batch: 0, Loss: 0.6944670081138611, Accuracy: 0.0\nText:  Почему Сан-Франциско оставляют богатые и захватывают бездомные Илон Маск сравнивает его пустеющий центр со сценами постапокалипсиса.\nPredicted: православие и мир, статья, в мире, коронавирус в россии\n-----------\nText:  В Ингушетии возрождается древняя техника ковроваляния Ее представят на форуме-выставке «Россия» на ВДНХ.\nPredicted: коронавирус в россии, саудовская аравия, новости - туризм, православие и мир\n-----------\n","output_type":"stream"},{"name":"stderr","text":"  4%|▎         | 41/1110 [00:14<06:23,  2.79it/s]","output_type":"stream"},{"name":"stdout","text":"Batch: 40, Loss: 0.3066663444042206, Accuracy: 0.0\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 81/1110 [00:29<06:11,  2.77it/s]","output_type":"stream"},{"name":"stdout","text":"Batch: 80, Loss: 0.05937468260526657, Accuracy: 0.28125\n","output_type":"stream"},{"name":"stderr","text":"  9%|▉         | 101/1110 [00:36<06:11,  2.71it/s]","output_type":"stream"},{"name":"stdout","text":"Text:  Почему Сан-Франциско оставляют богатые и захватывают бездомные Илон Маск сравнивает его пустеющий центр со сценами постапокалипсиса.\nPredicted: новость, наука и практика, образ жизни, питание\n-----------\nText:  В Ингушетии возрождается древняя техника ковроваляния Ее представят на форуме-выставке «Россия» на ВДНХ.\nPredicted: новость, наука и практика, образ жизни, питание\n-----------\n","output_type":"stream"},{"name":"stderr","text":" 11%|█         | 121/1110 [00:43<05:58,  2.76it/s]","output_type":"stream"},{"name":"stdout","text":"Batch: 120, Loss: 0.1782146692276001, Accuracy: 0.109375\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▍        | 161/1110 [00:58<05:44,  2.75it/s]","output_type":"stream"},{"name":"stdout","text":"Batch: 160, Loss: 0.23956480622291565, Accuracy: 0.0625\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 201/1110 [01:12<05:37,  2.69it/s]","output_type":"stream"},{"name":"stdout","text":"Batch: 200, Loss: 0.4061700403690338, Accuracy: 0.03125\nText:  Почему Сан-Франциско оставляют богатые и захватывают бездомные Илон Маск сравнивает его пустеющий центр со сценами постапокалипсиса.\nPredicted: газета.ру, интерьеры, новость, общество и государство\n-----------\nText:  В Ингушетии возрождается древняя техника ковроваляния Ее представят на форуме-выставке «Россия» на ВДНХ.\nPredicted: газета.ру, интерьеры, новость, общество и государство\n-----------\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▏       | 241/1110 [01:27<05:15,  2.76it/s]","output_type":"stream"},{"name":"stdout","text":"Batch: 240, Loss: 0.4179518222808838, Accuracy: 0.3125\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 281/1110 [01:41<05:00,  2.76it/s]","output_type":"stream"},{"name":"stdout","text":"Batch: 280, Loss: 0.92814701795578, Accuracy: 0.28125\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 301/1110 [01:49<05:01,  2.68it/s]","output_type":"stream"},{"name":"stdout","text":"Text:  Почему Сан-Франциско оставляют богатые и захватывают бездомные Илон Маск сравнивает его пустеющий центр со сценами постапокалипсиса.\nPredicted: новость, медновости, известия, гибель иранского генерала касема сулеймани\n-----------\nText:  В Ингушетии возрождается древняя техника ковроваляния Ее представят на форуме-выставке «Россия» на ВДНХ.\nPredicted: новость, медновости, известия, гибель иранского генерала касема сулеймани\n-----------\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▉       | 321/1110 [01:56<04:47,  2.75it/s]","output_type":"stream"},{"name":"stdout","text":"Batch: 320, Loss: 0.9547865390777588, Accuracy: 0.265625\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 361/1110 [02:10<04:32,  2.75it/s]","output_type":"stream"},{"name":"stdout","text":"Batch: 360, Loss: 0.9375000596046448, Accuracy: 0.25\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▌      | 401/1110 [02:25<04:22,  2.70it/s]","output_type":"stream"},{"name":"stdout","text":"Batch: 400, Loss: 1.0444079637527466, Accuracy: 0.203125\nText:  Почему Сан-Франциско оставляют богатые и захватывают бездомные Илон Маск сравнивает его пустеющий центр со сценами постапокалипсиса.\nPredicted: новость, статья, гибель иранского генерала касема сулеймани, конституция рф\n-----------\nText:  В Ингушетии возрождается древняя техника ковроваляния Ее представят на форуме-выставке «Россия» на ВДНХ.\nPredicted: новость, статья, гибель иранского генерала касема сулеймани, конституция рф\n-----------\n","output_type":"stream"},{"name":"stderr","text":" 40%|███▉      | 441/1110 [02:39<04:01,  2.77it/s]","output_type":"stream"},{"name":"stdout","text":"Batch: 440, Loss: 0.9786184430122375, Accuracy: 0.203125\n","output_type":"stream"},{"name":"stderr","text":" 42%|████▏     | 470/1110 [02:50<03:52,  2.76it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[147], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m logits \u001b[38;5;241m=\u001b[39m classifier_model(embeddings)\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(logits, keywords\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m---> 20\u001b[0m batch_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_batch\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m40\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     22\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m (logits\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m keywords\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel.to(device)\nmodel.eval()\nclassifier_model = KeywordClassifier(embedding_dim, number_keywords).to(device)\nloss_fn = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(classifier_model.parameters(), lr=1e-3)\n\nepoch = 6\ncheckpoint = torch.load(f\"/kaggle/working/checkpoint_{epoch}.pt\")\nclassifier_model.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nloss_history = checkpoint['loss_history']","metadata":{"execution":{"iopub.status.busy":"2024-04-21T11:01:05.055787Z","iopub.execute_input":"2024-04-21T11:01:05.056510Z","iopub.status.idle":"2024-04-21T11:01:05.087940Z","shell.execute_reply.started":"2024-04-21T11:01:05.056477Z","shell.execute_reply":"2024-04-21T11:01:05.087176Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"i = 0\nrow = full_dataset.data.iloc[i]\nprint(\"Text: \", row.Title, row.Description)\nres = predict_keywords(row.Title, row.Description, \"\")\nprint(\"Predicted:\", res)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T11:02:03.892424Z","iopub.execute_input":"2024-04-21T11:02:03.892783Z","iopub.status.idle":"2024-04-21T11:02:03.924593Z","shell.execute_reply.started":"2024-04-21T11:02:03.892755Z","shell.execute_reply":"2024-04-21T11:02:03.923736Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Text:  Сериал на выходные: едкая детективная комедия с Розановой и Снигирь Рассказываем о густонаселенном сериале «Престиж», где каждый герой наделен смачным пороком и парой скелетов в шкафу\nPredicted: ['дети 3-7 лет', 'наука и практика', 'опек', 'министерство финансов рф (минфин россии)', 'кндр (северная корея)', 'ирак', 'идлиб (мухафаза)', 'конституция рф', 'казахстан', 'беременность']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"full_dataset.shape","metadata":{}},{"cell_type":"code","source":"for i in np.random.choice(full_dataset.data.shape[0], 10):\n    row = full_dataset.data.iloc[i]\n    print(\"Text: \", row.Title, row.Description)\n    res = predict_keywords(row.Title, row.Description, \"\", top_keywords=10)\n    print(\"Predicted:\", \", \".join(res[4:]))\n    print(\"-----------\")","metadata":{"execution":{"iopub.status.busy":"2024-04-21T12:41:42.407416Z","iopub.execute_input":"2024-04-21T12:41:42.408253Z","iopub.status.idle":"2024-04-21T12:41:42.602651Z","shell.execute_reply.started":"2024-04-21T12:41:42.408219Z","shell.execute_reply":"2024-04-21T12:41:42.601652Z"},"trusted":true},"execution_count":144,"outputs":[{"name":"stdout","text":"Text:  Полуметровый пенис разрушил жизнь своего обладателя Мужчина не может вступать в половые сношения, работать и найти подходящую одежду.\nPredicted: религия и мировоззрение, протесты в белоруссии, биография, места, медицинский вестник, коронавирус в россии\n-----------\nText:  Специалист рассказал, что портит вашу кожу Неправильное питание, недостаток спорта и курение могут состарить на десять лет.\nPredicted: религия и мировоззрение, биография, медицинский вестник, протесты в белоруссии, места, коронавирус в россии\n-----------\nText:  СМИ: американские военные застрелили в Сирии мирного жителя \nPredicted: религия и мировоззрение, протесты в белоруссии, биография, места, медицинский вестник, евросоюз\n-----------\nText:  Вся правда о двухлетних детях: забавные фото Жить с двухлетним малышом – все равно что на вулкане: никогда не знаешь, что придет ребенку в голову через минуту. Зато именно в этом возрасте малыши способны на самые забавные выходки. Убедитесь в этом сами, посмотрев нашу подборку.\nPredicted: религия и мировоззрение, биография, протесты в белоруссии, медицинский вестник, места, евросоюз\n-----------\nText:  Бокс-офис первого уикенда октября – лидируют «Легенды ночных стражей» С 30 сентября по 3 октября 2010 года лидером проката в России стал Зак Снайдер с лентой «Легенды ночных стражей»\nPredicted: религия и мировоззрение, биография, протесты в белоруссии, места, медицинский вестник, евросоюз\n-----------\nText:  Никаких таблеток. Неожиданная защита от инфекции, придуманная животными \nPredicted: религия и мировоззрение, протесты в белоруссии, биография, места, медицинский вестник, евросоюз\n-----------\nText:  Ричард Гир: «На роль в \"Красотке\" меня уговорили с трудом» Ричард Гир был Брэдом Питтом своего времени, покорившим сердца миллионов женщин. Сегодня 63-летний актер — мудрый буддист и счастливый муж, но устоять перед его обаянием по-прежнему сложно.\nPredicted: религия и мировоззрение, биография, протесты в белоруссии, медицинский вестник, места, коронавирус в россии\n-----------\nText:  В 20 штатах в США могут снять ограничения из-за коронавируса до мая \nPredicted: религия и мировоззрение, биография, протесты в белоруссии, медицинский вестник, места, евросоюз\n-----------\nText:  Запрет фастфуда сделал его более популярным В итоге большему числу американцев угрожает ожирение.\nPredicted: религия и мировоззрение, биография, медицинский вестник, протесты в белоруссии, места, евросоюз\n-----------\nText:  США на учениях сымитировали ядерный удар по России \nPredicted: религия и мировоззрение, протесты в белоруссии, биография, места, медицинский вестник, коронавирус в россии\n-----------\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}